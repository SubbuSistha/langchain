```md id="chain_md_01"
# LangChain Chains â€” Quick Guide

---

## ğŸ“Œ What is a Chain
A **Chain** is a sequence of steps where:
```

output of one step â†’ input of next step

```

ğŸ‘‰ Used to build **LLM workflows**

---

## ğŸ”„ Flow Diagram

```

Input
â†“
Prompt
â†“
LLM
â†“
Parser
â†“
Output

````

---

## ğŸ”§ Example Chain

```python
chain = prompt | llm | parser

response = chain.invoke({"question": "India"})
````

---

## ğŸ”„ Internal Execution

```python
out1 = prompt.invoke(input)
out2 = llm.invoke(out1)
out3 = parser.invoke(out2)

return out3
```

---

## ğŸ”¹ Without Chain

```python
messages = prompt.format_messages(question="India")

response = llm.invoke(messages)

result = parser.parse(response.content)
```

---

## ğŸ”¹ With Chain

```python
chain = prompt | llm | parser

result = chain.invoke({"question": "India"})
```

---

## âš–ï¸ Comparison

| Aspect      | Without Chain  | With Chain  |
| ----------- | -------------- | ----------- |
| Code        | Multiple steps | Single line |
| Readability | Low            | High        |
| Errors      | More chances   | Less        |
| Reusability | Low            | High        |
| Maintenance | Hard           | Easy        |

---

## ğŸ§  Key Concept

ğŸ‘‰ Chain uses **pipe (`|`) operator**

```
step1 | step2 | step3
```

ğŸ‘‰ Means:

```
step1 output â†’ step2 input â†’ step3 input
```

---

## âš™ï¸ Runnable Concept

All components must implement:

```python
invoke(input) â†’ output
```

ğŸ‘‰ These are called **Runnables**

Examples:

* PromptTemplate
* LLM
* OutputParser

---

## ğŸ”¹ Custom Step Example

```python
from langchain_core.runnables import RunnableLambda

custom = RunnableLambda(lambda x: x + " processed")

chain = prompt | llm | custom
```

---

## âš ï¸ Important Rule

ğŸ‘‰ Output type of one step must match input type of next

---

## âŒ Invalid Example

```python
# step1 returns dict
# step2 expects string
```

ğŸ‘‰ Will fail

---

## ğŸ§  Mental Models

### 1. Function Chaining

```
f(g(h(x)))
```

---

### 2. Unix Pipe

```
cmd1 | cmd2 | cmd3
```

---

### 3. Java Stream

```
input â†’ map â†’ process â†’ collect
```

---

## ğŸ”¥ Sample Use Case

### Structured Output (Pydantic)

```python
chain = prompt | llm | parser

response = chain.invoke({"question": "India"})

print(response.country)
print(response.states)
```

---

### Flow

```
User Input
  â†“
Prompt (format)
  â†“
LLM (generate text)
  â†“
Parser (convert to object)
  â†“
Structured Output
```

---

## ğŸš€ Why Use Chains

* Clean code
* Automatic flow
* Reusable pipelines
* Standard LangChain pattern
* Used in Agents, RAG, Tools

---

## ğŸ§  Summary

ğŸ‘‰ Chain = **pipeline of runnables**
ğŸ‘‰ Each step implements `invoke()`
ğŸ‘‰ Output flows automatically to next step

```
input â†’ step1 â†’ step2 â†’ step3 â†’ output
```

```
```
